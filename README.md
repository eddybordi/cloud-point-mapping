# Robotique et algorithme de cloud point mapping / algorithme génétique

Il existe plusieurs techniques pour déterminer la position d'un robot dans l'espace. L'**odométrie** est par exemple couramment utilisée pour les systèmes qui se déplacent sur des roues (à partir d'une position connue, on mesure le mouvement de chaque roue - via son rayon, nombre de tours et angle - pour déterminer la position finale). Evidemment cette technique n'est pas utilisable sur des robots bipèdes ou quadrupèdes.

Il y a ensuite une technique appelée **localisation et cartographie** simultanées consistant comme le nom l'indique à construire une carte de l'environnement afin de marquer dessus sa position. Cette cartographie peut se faire de différentes manières, à l'aide d'une caméra 3D ou d'un LIDAR par exemple. Dans le cadre de mon projet c'est ce dernier que j'ai choisi. Le **LIDAR** est un appareil qui emet un laser et calcule le temps que met la lumière pour faire l'aller-retour, déterminant ainsi la distance à laquelle se trouvent les obstacles sur lesquels elle rebondit. Généralement, on utilise des versions 360°, montés sur un moteur tournant et renvoyant une série de distances/angles associés. Avec ces données, on peut déterminer quels sont les obstacles autour du robots et ainsi cartographier l'environnement.

Sur [ce jsfiddle](http://jsfiddle.net/eddybordi/rgp9tjuk/55/) nous pouvons voir deux scans effectués à deux positions différentes, le 1er avant que le robot ne se mette en mouvement, le second après qu'il ai avancé légèrement. Chacun des points composants les scans est une mesure du LIDAR (angle + distance), en les affichants en simultané on devine les contours d'une pièce.

Afin de déterminer la trajectoire et distance parcourue par le robot, on peut par exemple prendre un point similaire sur les deux scans et comparer le décalage entre les deux. Le souci c'est que si cette opération se révèle simple pour nous, une machine sans intelligence doit se reposer sur un algorithme bien spécifique pour y parvenir. On pourrait le faire avec du machine learning mais la solution algorithmique est ici plus rapide à mettre en place et plus précise. Ainsi, pour chaque point sur un scan, on calcule la distance avec les autres points environnents. Cela renvoie pour chacun de ces points une "somme" qu'on compare ensuite avec les sommes obtenues sur l'autre scan. On effectue ensuite un tri pour trouver les sommes les plus proches sur les deux scans. Le résultat obtenu correspond à des points similaires.

Cette opération est couteuse en temps de calcul. Sans optimisation, elle prendra une seule seconde sur un MacBook Pro mais sur un **Raspberry Pi** (qui est le type d'hardware utilisé en robotique), cela prendra plus de 10 secondes. Il est donc nécessaire d'optimiser l'algorithme avec une **technique d'élagage** qui permet d'atteindre un temps de calcul inférieur à 100ms.

Une fois le mapping et localisation effectués, il reste à implémenter un moyen pour le robot de déterminer le chemin le plus court d'un point à un autre au travers des obstacles sur son chemin, puisqu'une simple trajectoire droite ne sera pas toujours possible. On peut par exemple utiliser un [algorithme génétique](http://jsfiddle.net/eddybordi/mgbtc2ey/12/) (reprise du principe de "sélection naturelle"). Dans l'exemple que je montre ici où chaque carré en mouvement représente une "solution" pour une "génération" donnée, j'ai volontairement ralentit le calcul pour qu'on puisse voir les différentes étapes de manière décomposées. On comprend alors comment la sélection s'opère (grâce à l'émulation de **sélection et mutation**).